{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48eb567d-4db8-4322-b114-3537b267a9c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alimu\\anaconda3\\lib\\site-packages\\scipy\\__init__.py:155: UserWarning: A NumPy version >=1.18.5 and <1.25.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import pickle\n",
    "import heapq\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import LSTM, Dense, Activation\n",
    "from tensorflow.keras.optimizers import RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c41f22ad-bffc-43f3-a18d-830ed7a2f823",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_df = pd.read_csv(\"fake_or_real_news.csv\")\n",
    "text = list(text_df.text.values)\n",
    "joined_text = \" \".join(text)\n",
    "\n",
    "with open(\"joined_text.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(joined_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad1e9b16-0c9b-4bdb-a5fa-2c5eea7680e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "partial_text = joined_text[:100000] # in case of more a powerful hardware increase the number of joined characters for better predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7452e0cf-0c11-4bcc-b0b6-cc8bd8fb5612",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RegexpTokenizer(r\"\\w+\")\n",
    "tokens = tokenizer.tokenize(partial_text.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e816435e-09b1-4a82-80db-9da340b59c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_tokens = np.unique(tokens)\n",
    "unique_token_index = {token: index for index, token in enumerate(unique_tokens)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb56215e-a11f-4a2c-97a7-41e1f70614dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_words = 10\n",
    "input_words = []\n",
    "next_word = []\n",
    "\n",
    "for i in range(len(tokens) - n_words):\n",
    "    input_words.append(tokens[i:i + n_words])\n",
    "    next_word.append(tokens[i + n_words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "67376ed7-b1c7-4b33-817e-6b5dc3679777",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.zeros((len(input_words), n_words, len(unique_tokens)), dtype=bool)  # for each sample, n input words and then a boolean for each possible next word\n",
    "y = np.zeros((len(next_word), len(unique_tokens)), dtype=bool)  # for each sample a boolean for each possible next word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "67eb22b1-5de2-4b39-9cf2-a48ebe0e7e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, words in enumerate(input_words):\n",
    "    for j, word in enumerate(words):\n",
    "        X[i, j, unique_token_index[word]] = 1\n",
    "    y[i, unique_token_index[next_word[i]]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9b5a78e5-d8cb-4194-96a1-201f4cf5f34b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alimu\\anaconda3\\lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(n_words, len(unique_tokens)), return_sequences=True))\n",
    "model.add(LSTM(128))\n",
    "model.add(Dense(len(unique_tokens)))\n",
    "model.add(Activation(\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c43dc84a-eed0-480f-9b23-31f303c3e09b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 88ms/step - accuracy: 0.0472 - loss: 7.1313\n",
      "Epoch 2/10\n",
      "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 85ms/step - accuracy: 0.0596 - loss: 6.6919\n",
      "Epoch 3/10\n",
      "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 94ms/step - accuracy: 0.0654 - loss: 6.5317\n",
      "Epoch 4/10\n",
      "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 100ms/step - accuracy: 0.0741 - loss: 6.3837\n",
      "Epoch 5/10\n",
      "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 97ms/step - accuracy: 0.0874 - loss: 6.1860\n",
      "Epoch 6/10\n",
      "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 95ms/step - accuracy: 0.1023 - loss: 5.9198\n",
      "Epoch 7/10\n",
      "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 93ms/step - accuracy: 0.1122 - loss: 5.6487\n",
      "Epoch 8/10\n",
      "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 99ms/step - accuracy: 0.1356 - loss: 5.3729\n",
      "Epoch 9/10\n",
      "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 101ms/step - accuracy: 0.1570 - loss: 5.1308\n",
      "Epoch 10/10\n",
      "\u001b[1m 44/135\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 95ms/step - accuracy: 0.1953 - loss: 4.7088"
     ]
    }
   ],
   "source": [
    "optimizer = RMSprop(learning_rate=0.01)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n",
    "history = model.fit(X, y, batch_size=128, epochs=10, shuffle=True).history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c2ecba-b1e7-4182-9e68-43671eb6d1a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('textgenmodel_two.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d9a9f4-1cc0-4816-bf9f-e157f2f5aee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(\"textgenmodel_two.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c117b6-7de5-481d-ab4b-c6acc1e8d0bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_next_word(input_text, n_best):\n",
    "    input_text = input_text.lower()\n",
    "    X = np.zeros((1, n_words, len(unique_tokens)))\n",
    "    for i, word in enumerate(input_text.split()):\n",
    "        X[0, i, unique_token_index[word]] = 1\n",
    "        \n",
    "    predictions = model.predict(X)[0]\n",
    "    return np.argpartition(predictions, -n_best)[-n_best:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c7f5cb1-368d-42ce-aa8c-2120e7e12cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "possible = predict_next_word(\"Hello my name is \", 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd01427-2f75-4bd0-b5be-6ab41f4ccc93",
   "metadata": {},
   "outputs": [],
   "source": [
    "possible # gives us the index number of the possible next words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "832e548c-4ecf-40a0-8d9d-f8060945b7b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in possible:\n",
    "    print(unique_tokens[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37885cd4-e4cd-4203-a49c-bd143f8ea236",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(input_text, n_words, creativity=3):\n",
    "    word_sequence = input_text.split()\n",
    "    current = 0\n",
    "    for _ in range(n_words):\n",
    "        sub_sequence = \" \".join(tokenizer.tokenize(\" \".join(word_sequence).lower())[current:current+n_words])\n",
    "        try:\n",
    "            choice = unique_tokens[random.choice(predict_next_word(sub_sequence, creativity))]\n",
    "        except:\n",
    "            choice = random.choice(unique_tokens)\n",
    "        word_sequence.append(choice)\n",
    "        current += 1\n",
    "    return \" \".join(word_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dac37f5-f122-4bf6-95c2-d97cd6102dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_text(\"My friend John is \", 10, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d078d710-b011-4d2a-adef-3ec48bddb2cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
